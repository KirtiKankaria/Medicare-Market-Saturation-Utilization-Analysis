{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7aP0NyLO9x4",
        "outputId": "53731e92-4d23-490d-d959-0f86c144c75a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1247: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 0.7369714847590954\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1      0.791     0.741     0.765       506\n",
            "           2      0.382     0.479     0.425       374\n",
            "           3      0.866     0.819     0.842      1154\n",
            "\n",
            "    accuracy                          0.737      2034\n",
            "   macro avg      0.680     0.680     0.677      2034\n",
            "weighted avg      0.758     0.737     0.746      2034\n",
            "\n",
            "Confusion Matrix:\n",
            " [[375 105  26]\n",
            " [ 75 179 120]\n",
            " [ 24 185 945]]\n",
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 0.9124877089478859\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1      0.940     0.925     0.932       506\n",
            "           2      0.797     0.765     0.780       374\n",
            "           3      0.936     0.955     0.946      1154\n",
            "\n",
            "    accuracy                          0.912      2034\n",
            "   macro avg      0.891     0.882     0.886      2034\n",
            "weighted avg      0.911     0.912     0.912      2034\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 468   27   11]\n",
            " [  24  286   64]\n",
            " [   6   46 1102]]\n",
            "\n",
            "=== Gradient Boosting ===\n",
            "Accuracy: 0.7586037364798427\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1      0.811     0.771     0.790       506\n",
            "           2      0.423     0.551     0.479       374\n",
            "           3      0.888     0.821     0.853      1154\n",
            "\n",
            "    accuracy                          0.759      2034\n",
            "   macro avg      0.707     0.714     0.707      2034\n",
            "weighted avg      0.784     0.759     0.769      2034\n",
            "\n",
            "Confusion Matrix:\n",
            " [[390  99  17]\n",
            " [ 66 206 102]\n",
            " [ 25 182 947]]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# STEP 1: Load data\n",
        "df = pd.read_excel(\"/content/Neurology.xlsx\", sheet_name=\"Data\")\n",
        "\n",
        "# STEP 2: Keep only numeric features and extract target\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "X = numeric_df.drop(columns=['Health Behaviors Quartile'])\n",
        "y = df['Health Behaviors Quartile']\n",
        "\n",
        "# If target is non-numeric, encode it\n",
        "if y.dtype == 'object':\n",
        "    le = LabelEncoder()\n",
        "    y = le.fit_transform(y)\n",
        "\n",
        "# STEP 3: Impute missing values with -1 AND add missingness indicators\n",
        "# 3a. Create missing-indicator DataFrame\n",
        "missing_ind = X.isna().astype(int).add_suffix('_missing')\n",
        "\n",
        "# 3b. Impute all NaNs with -1\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=-1)\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
        "\n",
        "# 3c. Concatenate indicators\n",
        "X_aug = pd.concat([X_imputed, missing_ind], axis=1)\n",
        "\n",
        "# STEP 4: Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_aug)\n",
        "\n",
        "# STEP 5: PCA (retain 95% of variance)\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# STEP 6: Train/Test split (stratify to preserve class proportions)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# STEP 7: SMOTE on training set only\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# STEP 8: Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        multi_class='multinomial',\n",
        "        solver='lbfgs',\n",
        "        max_iter=1000,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# STEP 9: Train, predict, and evaluate\n",
        "def evaluate(name, model, X_tr, y_tr, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_te, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_te, y_pred, digits=3))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, y_pred))\n",
        "\n",
        "for name, mdl in models.items():\n",
        "    evaluate(name, mdl, X_train_res, y_train_res, X_test, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# STEP 1: Load data\n",
        "df = pd.read_excel(\"/content/Neurology.xlsx\", sheet_name=\"Data\")\n",
        "\n",
        "# STEP 2: Keep only numeric features and extract binary target 'Health Ranking'\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "X = numeric_df.drop(columns=['Health Ranking'])\n",
        "y = df['Health Ranking']\n",
        "\n",
        "# STEP 3: Impute missing values with -1 AND add missingness indicators\n",
        "missing_ind = X.isna().astype(int).add_suffix('_missing')\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=-1)\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
        "X_aug = pd.concat([X_imputed, missing_ind], axis=1)\n",
        "\n",
        "# STEP 4: Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_aug)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X_aug.columns)\n",
        "# Drop highly correlated features before statsmodels\n",
        "def drop_high_corr_features(df, threshold=0.99):\n",
        "    corr_matrix = df.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "    return df.drop(columns=to_drop)\n",
        "\n",
        "X_scaled_df_dedup = drop_high_corr_features(X_scaled_df)\n",
        "X_scaled_df_dedup = X_scaled_df_dedup.loc[:, X_scaled_df_dedup.std() > 1e-6]  # drop constant columns\n",
        "\n",
        "# Add constant for intercept and fit model\n",
        "X_sm = sm.add_constant(X_scaled_df_dedup)\n",
        "logit_model = sm.Logit(y, X_sm).fit()\n",
        "print(\"\\n=== Logistic Regression Summary (statsmodels) ===\")\n",
        "print(logit_model.summary())\n",
        "\n",
        "\n",
        "# STEP 5: PCA (retain 95% of variance)\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# STEP 6: Train/Test split (stratify to preserve class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# STEP 7: Apply SMOTE only to training set\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# STEP 8: Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        solver='liblinear',\n",
        "        class_weight='balanced',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# STEP 9: Train, predict, and evaluate\n",
        "def evaluate(name, model, X_tr, y_tr, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_te, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_te, y_pred, digits=3))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, y_pred))\n",
        "\n",
        "for name, mdl in models.items():\n",
        "    evaluate(name, mdl, X_train_res, y_train_res, X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elwtV2FvDj98",
        "outputId": "96488208-4e0c-4b3b-c5dd-d3133e6e5e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.009790\n",
            "         Iterations 14\n",
            "\n",
            "=== Logistic Regression Summary (statsmodels) ===\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:         Health Ranking   No. Observations:                 2505\n",
            "Model:                          Logit   Df Residuals:                     2475\n",
            "Method:                           MLE   Df Model:                           29\n",
            "Date:                Fri, 11 Apr 2025   Pseudo R-squ.:                  0.9858\n",
            "Time:                        22:59:37   Log-Likelihood:                -24.524\n",
            "converged:                       True   LL-Null:                       -1731.3\n",
            "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
            "========================================================================================================================\n",
            "                                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "const                                                   -2.4418      0.761     -3.210      0.001      -3.933      -0.951\n",
            "FIPS_Code                                               -0.1282      0.514     -0.249      0.803      -1.136       0.880\n",
            "Deaths                                                   5.9208      3.240      1.828      0.068      -0.429      12.271\n",
            "% Fair or Poor Health                                    1.3485      2.176      0.620      0.535      -2.916       5.613\n",
            "Average Number of Physically Unhealthy Days              1.4145      3.601      0.393      0.694      -5.643       8.472\n",
            "Average Number of Mentally Unhealthy Days               -0.4092      1.766     -0.232      0.817      -3.871       3.053\n",
            "% Adults Reporting Currently Smoking                    -0.1487      1.538     -0.097      0.923      -3.163       2.866\n",
            "% Adults with Obesity                                   -0.2295      0.953     -0.241      0.810      -2.098       1.639\n",
            "# Primary Care Physicians                              -13.0594      4.882     -2.675      0.007     -22.628      -3.491\n",
            "# Mental Health Providers                                2.6090      1.969      1.325      0.185      -1.251       6.469\n",
            "Preventable Hospitalization Rate                        -0.3173      0.641     -0.495      0.620      -1.573       0.938\n",
            "number_of_fee_for_service_beneficiaries                  4.0960      3.552      1.153      0.249      -2.867      11.059\n",
            "number_of_providers                                     -2.9929      2.982     -1.004      0.316      -8.838       2.852\n",
            "average_number_of_users_per_provider                    -0.3367      1.051     -0.320      0.749      -2.397       1.724\n",
            "percentage_of_users_out_of_ffs_beneficiaries             0.3283      0.741      0.443      0.658      -1.124       1.781\n",
            "number_of_dual_eligible_users                            4.2877      1.840      2.331      0.020       0.682       7.893\n",
            "percentage_of_dual_eligible_users_out_of_total_users    -0.4496      0.827     -0.544      0.586      -2.070       1.170\n",
            "total_payment                                           -4.3989      3.452     -1.274      0.203     -11.165       2.367\n",
            "Population                                              -4.0909      3.489     -1.172      0.241     -10.929       2.748\n",
            "Life Expectancy                                         -0.7276      0.985     -0.738      0.460      -2.659       1.204\n",
            "% Frequent Physical Distress                            -4.6057      4.931     -0.934      0.350     -14.270       5.059\n",
            "% Frequent Mental Distress                               1.9141      2.419      0.791      0.429      -2.827       6.655\n",
            "# Uninsured Adults                                       4.9191      1.652      2.977      0.003       1.681       8.157\n",
            "Health Quartile                                         14.9177      1.954      7.635      0.000      11.088      18.747\n",
            "Deaths_missing                                           0.0480      0.540      0.089      0.929      -1.011       1.107\n",
            "# Primary Care Physicians_missing                       -0.1314      0.732     -0.180      0.857      -1.565       1.302\n",
            "# Mental Health Providers_missing                        0.0047      0.536      0.009      0.993      -1.046       1.056\n",
            "Preventable Hospitalization Rate_missing                 0.0288      0.476      0.061      0.952      -0.903       0.961\n",
            "average_number_of_users_per_provider_missing            -0.0639      1.149     -0.056      0.956      -2.316       2.189\n",
            "Population_missing                                      -0.1827      0.592     -0.309      0.758      -1.343       0.977\n",
            "========================================================================================================================\n",
            "\n",
            "Possibly complete quasi-separation: A fraction 0.53 of observations can be\n",
            "perfectly predicted. This might indicate that there is complete\n",
            "quasi-separation. In this case some parameters will not be identified.\n",
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 1.0\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      1.000     1.000     1.000       266\n",
            "           1      1.000     1.000     1.000       235\n",
            "\n",
            "    accuracy                          1.000       501\n",
            "   macro avg      1.000     1.000     1.000       501\n",
            "weighted avg      1.000     1.000     1.000       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[266   0]\n",
            " [  0 235]]\n",
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 0.9840319361277445\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.978     0.992     0.985       266\n",
            "           1      0.991     0.974     0.983       235\n",
            "\n",
            "    accuracy                          0.984       501\n",
            "   macro avg      0.985     0.983     0.984       501\n",
            "weighted avg      0.984     0.984     0.984       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[264   2]\n",
            " [  6 229]]\n",
            "\n",
            "=== Gradient Boosting ===\n",
            "Accuracy: 0.9880239520958084\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.989     0.989     0.989       266\n",
            "           1      0.987     0.987     0.987       235\n",
            "\n",
            "    accuracy                          0.988       501\n",
            "   macro avg      0.988     0.988     0.988       501\n",
            "weighted avg      0.988     0.988     0.988       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[263   3]\n",
            " [  3 232]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import statsmodels.api as sm\n",
        "# STEP 1: Load data\n",
        "df = pd.read_excel(\"/content/Neurology.xlsx\", sheet_name=\"Data\")\n",
        "\n",
        "# STEP 2: Keep only numeric features and extract binary target 'Health Ranking'\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "\n",
        "\n",
        "# Drop 'Health Ranking' from features, and also drop 'Health Quartile' and 'FIPS_Code' if they exist\n",
        "X = numeric_df.drop(columns=['Health Ranking'])\n",
        "for col in ['Health Quartile', 'FIPS_Code']:\n",
        "    if col in X.columns:\n",
        "        X = X.drop(columns=[col])\n",
        "\n",
        "y = df['Health Ranking']\n",
        "\n",
        "# STEP 3: Impute missing values with -1 AND add missingness indicators\n",
        "missing_ind = X.isna().astype(int).add_suffix('_missing')\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=-1)\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
        "X_aug = pd.concat([X_imputed, missing_ind], axis=1)\n",
        "\n",
        "# STEP 4: Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_aug)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X_aug.columns)\n",
        "\n",
        "# Drop highly correlated features before statsmodels\n",
        "def drop_high_corr_features(df, threshold=0.99):\n",
        "    corr_matrix = df.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "    return df.drop(columns=to_drop)\n",
        "\n",
        "X_scaled_df_dedup = drop_high_corr_features(X_scaled_df)\n",
        "X_scaled_df_dedup = X_scaled_df_dedup.loc[:, X_scaled_df_dedup.std() > 1e-6]  # drop near-constant columns\n",
        "\n",
        "# STEP 4.5: Statsmodels logistic regression with p-value filtering\n",
        "X_sm = sm.add_constant(X_scaled_df_dedup)\n",
        "logit_model = sm.Logit(y, X_sm).fit()\n",
        "print(\"\\n=== Full Logistic Regression Summary ===\")\n",
        "print(logit_model.summary())\n",
        "\n",
        "# Filter variables with p-values <= 0.05\n",
        "significant_vars = logit_model.pvalues[logit_model.pvalues <= 0.05].index\n",
        "X_sm_significant = X_sm[significant_vars]\n",
        "\n",
        "# Refit model using only significant features\n",
        "logit_model_significant = sm.Logit(y, X_sm_significant).fit()\n",
        "print(\"\\n=== Logistic Regression Summary (Only p ≤ 0.05 Variables) ===\")\n",
        "print(logit_model_significant.summary())\n",
        "\n",
        "# STEP 5: PCA (retain 95% of variance)\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# STEP 6: Train/Test split (stratify to preserve class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# STEP 8: Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        solver='liblinear',\n",
        "        class_weight='balanced',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# STEP 9: Train, predict, and evaluate\n",
        "def evaluate(name, model, X_tr, y_tr, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_te, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_te, y_pred, digits=3))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, y_pred))\n",
        "\n",
        "for name, mdl in models.items():\n",
        "    evaluate(name, mdl, X_train, y_train, X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEriQjuNAjD7",
        "outputId": "d094557f-fcb2-4f5b-adfb-24975e9f011b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.469331\n",
            "         Iterations 9\n",
            "\n",
            "=== Full Logistic Regression Summary ===\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:         Health Ranking   No. Observations:                 2505\n",
            "Model:                          Logit   Df Residuals:                     2477\n",
            "Method:                           MLE   Df Model:                           27\n",
            "Date:                Thu, 17 Apr 2025   Pseudo R-squ.:                  0.3209\n",
            "Time:                        13:26:38   Log-Likelihood:                -1175.7\n",
            "converged:                       True   LL-Null:                       -1731.3\n",
            "Covariance Type:            nonrobust   LLR p-value:                6.131e-217\n",
            "========================================================================================================================\n",
            "                                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "const                                                   -0.4948      0.076     -6.502      0.000      -0.644      -0.346\n",
            "Deaths                                                   2.4866      0.501      4.965      0.000       1.505       3.468\n",
            "% Fair or Poor Health                                   -1.4228      0.233     -6.105      0.000      -1.880      -0.966\n",
            "Average Number of Physically Unhealthy Days             -2.2726      0.354     -6.424      0.000      -2.966      -1.579\n",
            "Average Number of Mentally Unhealthy Days                0.5941      0.180      3.304      0.001       0.242       0.946\n",
            "% Adults Reporting Currently Smoking                     1.1145      0.144      7.726      0.000       0.832       1.397\n",
            "% Adults with Obesity                                    0.4366      0.097      4.488      0.000       0.246       0.627\n",
            "# Primary Care Physicians                               -3.8949      0.621     -6.268      0.000      -5.113      -2.677\n",
            "# Mental Health Providers                                1.7871      0.374      4.779      0.000       1.054       2.520\n",
            "Preventable Hospitalization Rate                        -0.1756      0.065     -2.687      0.007      -0.304      -0.048\n",
            "number_of_fee_for_service_beneficiaries                  0.9567      0.570      1.679      0.093      -0.160       2.073\n",
            "number_of_providers                                     -0.6508      0.452     -1.439      0.150      -1.537       0.235\n",
            "average_number_of_users_per_provider                    -0.0939      0.113     -0.833      0.405      -0.315       0.127\n",
            "percentage_of_users_out_of_ffs_beneficiaries             0.0219      0.073      0.300      0.764      -0.121       0.165\n",
            "number_of_dual_eligible_users                            1.0683      0.334      3.198      0.001       0.414       1.723\n",
            "percentage_of_dual_eligible_users_out_of_total_users     0.1844      0.075      2.461      0.014       0.038       0.331\n",
            "total_payment                                           -0.8971      0.519     -1.729      0.084      -1.914       0.120\n",
            "Population                                              -0.6020      0.492     -1.223      0.221      -1.567       0.362\n",
            "Life Expectancy                                         -0.2537      0.100     -2.532      0.011      -0.450      -0.057\n",
            "% Frequent Physical Distress                             5.2015      0.494     10.527      0.000       4.233       6.170\n",
            "% Frequent Mental Distress                              -2.1658      0.255     -8.495      0.000      -2.665      -1.666\n",
            "# Uninsured Adults                                      -1.3518      0.380     -3.557      0.000      -2.097      -0.607\n",
            "Deaths_missing                                           0.0424      0.055      0.771      0.441      -0.065       0.150\n",
            "# Primary Care Physicians_missing                       -0.1026      0.050     -2.040      0.041      -0.201      -0.004\n",
            "# Mental Health Providers_missing                       -0.0385      0.048     -0.795      0.427      -0.134       0.056\n",
            "Preventable Hospitalization Rate_missing                -0.0584      0.070     -0.839      0.402      -0.195       0.078\n",
            "average_number_of_users_per_provider_missing             0.0978      0.112      0.872      0.383      -0.122       0.318\n",
            "Population_missing                                      -0.0833      0.061     -1.375      0.169      -0.202       0.035\n",
            "========================================================================================================================\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.473479\n",
            "         Iterations 9\n",
            "\n",
            "=== Logistic Regression Summary (Only p ≤ 0.05 Variables) ===\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:         Health Ranking   No. Observations:                 2505\n",
            "Model:                          Logit   Df Residuals:                     2488\n",
            "Method:                           MLE   Df Model:                           16\n",
            "Date:                Thu, 17 Apr 2025   Pseudo R-squ.:                  0.3149\n",
            "Time:                        13:26:38   Log-Likelihood:                -1186.1\n",
            "converged:                       True   LL-Null:                       -1731.3\n",
            "Covariance Type:            nonrobust   LLR p-value:                4.711e-222\n",
            "========================================================================================================================\n",
            "                                                           coef    std err          z      P>|z|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------------------------------------------------\n",
            "const                                                   -0.4152      0.064     -6.490      0.000      -0.541      -0.290\n",
            "Deaths                                                   1.9900      0.347      5.731      0.000       1.309       2.670\n",
            "% Fair or Poor Health                                   -1.4777      0.229     -6.466      0.000      -1.926      -1.030\n",
            "Average Number of Physically Unhealthy Days             -2.3629      0.347     -6.810      0.000      -3.043      -1.683\n",
            "Average Number of Mentally Unhealthy Days                0.5640      0.175      3.221      0.001       0.221       0.907\n",
            "% Adults Reporting Currently Smoking                     1.1305      0.141      7.990      0.000       0.853       1.408\n",
            "% Adults with Obesity                                    0.4451      0.096      4.647      0.000       0.257       0.633\n",
            "# Primary Care Physicians                               -3.7654      0.577     -6.531      0.000      -4.895      -2.635\n",
            "# Mental Health Providers                                2.0218      0.321      6.304      0.000       1.393       2.650\n",
            "Preventable Hospitalization Rate                        -0.1823      0.064     -2.840      0.005      -0.308      -0.057\n",
            "number_of_dual_eligible_users                            0.3939      0.116      3.400      0.001       0.167       0.621\n",
            "percentage_of_dual_eligible_users_out_of_total_users     0.1093      0.061      1.795      0.073      -0.010       0.229\n",
            "Life Expectancy                                         -0.2681      0.098     -2.727      0.006      -0.461      -0.075\n",
            "% Frequent Physical Distress                             5.3286      0.484     11.009      0.000       4.380       6.277\n",
            "% Frequent Mental Distress                              -2.1367      0.251     -8.529      0.000      -2.628      -1.646\n",
            "# Uninsured Adults                                      -1.3875      0.334     -4.158      0.000      -2.042      -0.734\n",
            "# Primary Care Physicians_missing                       -0.1020      0.049     -2.093      0.036      -0.198      -0.007\n",
            "========================================================================================================================\n",
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 0.720558882235529\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.748     0.714     0.731       266\n",
            "           1      0.692     0.728     0.710       235\n",
            "\n",
            "    accuracy                          0.721       501\n",
            "   macro avg      0.720     0.721     0.720       501\n",
            "weighted avg      0.722     0.721     0.721       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[190  76]\n",
            " [ 64 171]]\n",
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 0.7644710578842315\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.770     0.793     0.781       266\n",
            "           1      0.758     0.732     0.745       235\n",
            "\n",
            "    accuracy                          0.764       501\n",
            "   macro avg      0.764     0.763     0.763       501\n",
            "weighted avg      0.764     0.764     0.764       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[211  55]\n",
            " [ 63 172]]\n",
            "\n",
            "=== Gradient Boosting ===\n",
            "Accuracy: 0.7684630738522954\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.786     0.774     0.780       266\n",
            "           1      0.749     0.762     0.755       235\n",
            "\n",
            "    accuracy                          0.768       501\n",
            "   macro avg      0.768     0.768     0.768       501\n",
            "weighted avg      0.769     0.768     0.769       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[206  60]\n",
            " [ 56 179]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# STEP 1: Load data\n",
        "df = pd.read_excel(\"/content/Neurology.xlsx\", sheet_name=\"Data\")\n",
        "\n",
        "# STEP 2: Keep only numeric features and extract binary target 'Health Ranking'\n",
        "numeric_df = df.select_dtypes(include=[np.number])\n",
        "X = numeric_df.drop(columns=['Health Ranking'])\n",
        "for col in ['Health Quartile', 'FIPS_Code']:\n",
        "    if col in X.columns:\n",
        "        X = X.drop(columns=[col])\n",
        "y = df['Health Ranking']\n",
        "\n",
        "\n",
        "# STEP 3: Impute missing values with -1 AND add missingness indicators\n",
        "missing_ind = X.isna().astype(int).add_suffix('_missing')\n",
        "imputer = SimpleImputer(strategy='constant', fill_value=-1)\n",
        "X_imputed = pd.DataFrame(imputer.fit_transform(X), columns=X.columns, index=X.index)\n",
        "X_aug = pd.concat([X_imputed, missing_ind], axis=1)\n",
        "\n",
        "# STEP 3.5: Remove specific columns and all *_missing columns\n",
        "columns_to_remove = [\n",
        "    'Mental Health Providers',\n",
        "    'Average Number of Mentally Unhealthy Days',\n",
        "    'Preventable Hospitalization Rate_missing',\n",
        "    'number_of_dual_eligible_users_missing','# Mental Health Providers' ,\n",
        "'Mental Health Provider Rate', '% Frequent Mental Distress'\n",
        "]\n",
        "# Remove listed columns if they exist\n",
        "X_aug = X_aug.drop(columns=[col for col in columns_to_remove if col in X_aug.columns])\n",
        "\n",
        "# Remove all *_missing columns\n",
        "X_aug = X_aug.drop(columns=[col for col in X_aug.columns if col.endswith('_missing')])\n",
        "\n",
        "# STEP 4: Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_aug)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X_aug.columns)\n",
        "\n",
        "# Drop highly correlated features\n",
        "def drop_high_corr_features(df, threshold=0.99):\n",
        "    corr_matrix = df.corr().abs()\n",
        "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
        "    return df.drop(columns=to_drop)\n",
        "\n",
        "X_scaled_df_dedup = drop_high_corr_features(X_scaled_df)\n",
        "X_scaled_df_dedup = X_scaled_df_dedup.loc[:, X_scaled_df_dedup.std() > 1e-6]  # drop near-constant columns\n",
        "\n",
        "# STEP 4.5: Backward Elimination Function\n",
        "def backward_elimination(X, y, sl=0.05):\n",
        "    X_ = sm.add_constant(X.copy())\n",
        "    while True:\n",
        "        model = sm.Logit(y, X_).fit(disp=False)\n",
        "        p_values = model.pvalues\n",
        "        max_p = p_values.max()\n",
        "        if max_p > sl:\n",
        "            worst_feature = p_values.idxmax()\n",
        "            print(f\"Removing '{worst_feature}' with p = {max_p:.4f}\")\n",
        "            X_ = X_.drop(columns=[worst_feature])\n",
        "        else:\n",
        "            break\n",
        "    final_model = sm.Logit(y, X_).fit()\n",
        "    return final_model, X_\n",
        "\n",
        "# STEP 4.6: Apply Backward Elimination\n",
        "logit_model_optimized, X_selected = backward_elimination(X_scaled_df_dedup, y)\n",
        "\n",
        "print(\"\\n=== Logistic Regression Summary (Backward Elimination) ===\")\n",
        "print(logit_model_optimized.summary())\n",
        "\n",
        "# STEP 5: PCA (retain 95% of variance)\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# STEP 6: Train/Test split (stratify to preserve class balance)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_pca, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "# STEP 8: Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(\n",
        "        solver='liblinear',\n",
        "        class_weight='balanced',\n",
        "        max_iter=1000,\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# STEP 9: Train, predict, and evaluate\n",
        "def evaluate(name, model, X_tr, y_tr, X_te, y_te):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "    print(f\"\\n=== {name} ===\")\n",
        "    print(\"Accuracy:\", accuracy_score(y_te, y_pred))\n",
        "    print(\"Classification Report:\\n\", classification_report(y_te, y_pred, digits=3))\n",
        "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_te, y_pred))\n",
        "\n",
        "for name, mdl in models.items():\n",
        "    evaluate(name, mdl, X_train, y_train, X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06jB13O87WuZ",
        "outputId": "3c500d21-779b-4e20-dbaa-2e169259615d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Removing 'percentage_of_users_out_of_ffs_beneficiaries' with p = 0.8918\n",
            "Removing 'Population' with p = 0.6083\n",
            "Removing 'percentage_of_dual_eligible_users_out_of_total_users' with p = 0.2878\n",
            "Removing 'number_of_providers' with p = 0.0728\n",
            "Optimization terminated successfully.\n",
            "         Current function value: 0.503256\n",
            "         Iterations 9\n",
            "\n",
            "=== Logistic Regression Summary (Backward Elimination) ===\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:         Health Ranking   No. Observations:                 2505\n",
            "Model:                          Logit   Df Residuals:                     2490\n",
            "Method:                           MLE   Df Model:                           14\n",
            "Date:                Thu, 17 Apr 2025   Pseudo R-squ.:                  0.2718\n",
            "Time:                        16:57:27   Log-Likelihood:                -1260.7\n",
            "converged:                       True   LL-Null:                       -1731.3\n",
            "Covariance Type:            nonrobust   LLR p-value:                6.206e-192\n",
            "===============================================================================================================\n",
            "                                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------------------------------\n",
            "const                                          -0.4096      0.067     -6.104      0.000      -0.541      -0.278\n",
            "Deaths                                          1.4555      0.396      3.678      0.000       0.680       2.231\n",
            "% Fair or Poor Health                          -1.1104      0.216     -5.152      0.000      -1.533      -0.688\n",
            "Average Number of Physically Unhealthy Days    -3.1070      0.306    -10.163      0.000      -3.706      -2.508\n",
            "% Adults Reporting Currently Smoking            0.3547      0.116      3.055      0.002       0.127       0.582\n",
            "% Adults with Obesity                           0.4667      0.093      5.037      0.000       0.285       0.648\n",
            "# Primary Care Physicians                      -2.2422      0.457     -4.906      0.000      -3.138      -1.346\n",
            "Preventable Hospitalization Rate               -0.1891      0.061     -3.092      0.002      -0.309      -0.069\n",
            "number_of_fee_for_service_beneficiaries         1.0334      0.356      2.903      0.004       0.336       1.731\n",
            "average_number_of_users_per_provider           -0.1441      0.055     -2.629      0.009      -0.252      -0.037\n",
            "number_of_dual_eligible_users                   1.3957      0.287      4.870      0.000       0.834       1.957\n",
            "total_payment                                  -1.6885      0.439     -3.848      0.000      -2.548      -0.828\n",
            "Life Expectancy                                -0.2623      0.094     -2.800      0.005      -0.446      -0.079\n",
            "% Frequent Physical Distress                    4.7028      0.443     10.615      0.000       3.834       5.571\n",
            "# Uninsured Adults                             -0.8614      0.289     -2.977      0.003      -1.429      -0.294\n",
            "===============================================================================================================\n",
            "\n",
            "=== Logistic Regression ===\n",
            "Accuracy: 0.6946107784431138\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.725     0.684     0.704       266\n",
            "           1      0.664     0.706     0.685       235\n",
            "\n",
            "    accuracy                          0.695       501\n",
            "   macro avg      0.695     0.695     0.694       501\n",
            "weighted avg      0.696     0.695     0.695       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[182  84]\n",
            " [ 69 166]]\n",
            "\n",
            "=== Random Forest ===\n",
            "Accuracy: 0.7584830339321357\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.756     0.805     0.780       266\n",
            "           1      0.761     0.706     0.733       235\n",
            "\n",
            "    accuracy                          0.758       501\n",
            "   macro avg      0.759     0.755     0.756       501\n",
            "weighted avg      0.759     0.758     0.758       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[214  52]\n",
            " [ 69 166]]\n",
            "\n",
            "=== Gradient Boosting ===\n",
            "Accuracy: 0.7325349301397206\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0      0.729     0.789     0.758       266\n",
            "           1      0.737     0.668     0.701       235\n",
            "\n",
            "    accuracy                          0.733       501\n",
            "   macro avg      0.733     0.729     0.730       501\n",
            "weighted avg      0.733     0.733     0.731       501\n",
            "\n",
            "Confusion Matrix:\n",
            " [[210  56]\n",
            " [ 78 157]]\n"
          ]
        }
      ]
    }
  ]
}